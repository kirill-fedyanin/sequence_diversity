{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi there!\n"
     ]
    }
   ],
   "source": [
    "print(\"hi there!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:50:37.629902801Z",
     "start_time": "2023-07-19T07:50:37.628813929Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:50:39.489418109Z",
     "start_time": "2023-07-19T07:50:39.484885936Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "from transformers import TemperatureLogitsWarper, LogitsProcessorList\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n",
      "- configuration_RW.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n",
      "- modelling_RW.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7d16844ec8e491b9866e3b2e65696ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "803687ae5e1b4cb68b8a78804817407c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "RWForCausalLM(\n  (transformer): RWModel(\n    (word_embeddings): Embedding(65024, 4544)\n    (h): ModuleList(\n      (0-31): 32 x DecoderLayer(\n        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n        (self_attention): Attention(\n          (maybe_rotary): RotaryEmbedding()\n          (query_key_value): Linear(in_features=4544, out_features=4672, bias=False)\n          (dense): Linear(in_features=4544, out_features=4544, bias=False)\n          (attention_dropout): Dropout(p=0.0, inplace=False)\n        )\n        (mlp): MLP(\n          (dense_h_to_4h): Linear(in_features=4544, out_features=18176, bias=False)\n          (act): GELU(approximate='none')\n          (dense_4h_to_h): Linear(in_features=18176, out_features=4544, bias=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\n)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"huggyllama/llama-7b\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"huggyllama/llama-7b\")\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(\"lmsys/vicuna-13b-v1.3\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"lmsys/vicuna-13b-v1.3\")\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(\"lmsys/vicuna-7b-v1.3\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"lmsys/vicuna-7b-v1.3\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-7b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"tiiuae/falcon-7b\")\n",
    "\n",
    "model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T08:14:18.306973723Z",
     "start_time": "2023-07-19T08:12:30.283589217Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def recover_oom():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "recover_oom()\n",
    "\n",
    "\n",
    "def sampling(tokens):\n",
    "    return model.generate(tokens, max_new_tokens=50, eos_token_id=[2, 13], do_sample=True)\n",
    "\n",
    "def infer(func, prompt, repeats=5, verbose=False):\n",
    "    sep = \"\\n***********\\n\\n\"\n",
    "    if verbose:\n",
    "        print(prompt, end=sep)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "    input_ids = input_ids.repeat((repeats, 1))\n",
    "    gen_output = func(input_ids)\n",
    "    responses = [tokenizer.decode(sequence).replace('<unk>', '') for sequence in gen_output]\n",
    "    responses = [r[len(prompt) + 5:].strip() for r in responses]\n",
    "    if verbose:\n",
    "        print(*responses, sep=sep)\n",
    "    return responses\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T08:14:18.481481251Z",
     "start_time": "2023-07-19T08:14:18.307295083Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# def sampling(tokens):\n",
    "#     return model.sample(\n",
    "#         tokens, logits_warper=logits_warper, max_length=80, eos_token_id=[2, 13]\n",
    "#     )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:39:01.083742446Z",
     "start_time": "2023-07-11T11:39:01.083489989Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13108\n",
      "Counter({6: 5019, 5: 3867, 4: 2935, 3: 1216, 2: 71})\n"
     ]
    }
   ],
   "source": [
    "# open the feud dataset\n",
    "import json\n",
    "\n",
    "with open('../data_store/question_db.json', 'r') as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "\n",
    "print(len(questions))\n",
    "lengths = [len(q['answers']) for q in questions]\n",
    "from collections import Counter\n",
    "print(Counter(lengths))\n",
    "qs = [q for q in questions if len(q['answers']) == 3][:5]\n",
    "questions = [q for q in questions if len(q['answers']) == 6]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:51:55.564481081Z",
     "start_time": "2023-07-19T07:51:55.564172576Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def template(prompt):\n",
    "    instruction = 'Your task is to provide one brief answer, up to 10 words, that most people would agree with.\\n'\n",
    "    instruction += \"\\n\\n\".join([\n",
    "        f\"Q: {q['question']}\\nA: {q['answers'][2]['text']}\" for q in qs[1:3]\n",
    "    ])\n",
    "    instruction += f\"\\n\\nQ: {prompt}\\nA: \"\n",
    "    return instruction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T08:04:59.433633697Z",
     "start_time": "2023-07-19T08:04:59.023472125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Name Something A Magician Might Make Disappear', 'link': '/question/name-something-a-magician-might-make-disappear', 'answers': [{'text': 'Rabbit', 'points': 43}, {'text': 'Assistant/Spectator', 'points': 36}, {'text': 'Bird', 'points': 7}, {'text': 'Money', 'points': 4}, {'text': 'Flowers', 'points': 3}, {'text': 'her/himself', 'points': 3}]}\n",
      "Name Something A Magician Might Make Disappear\n",
      "Note\n",
      "\n",
      "Q: Name Something You May Not Want To Rent.\n",
      "A: An Elephant\n",
      "\n",
      "Q: Name Something That When Shaken Cannot Be Replenished.\n",
      "A: Coffee\n",
      "\n",
      "Q: Name One Thing People Don\n",
      "cally) A Girl!\n",
      "\n",
      "Q: Name Something You Might Find In A Church.\n",
      "A: The Devil\n",
      "\n",
      "Q: Name A Profession In Which It Is Not Necessary To Hire The Best Man For The Job.\n",
      "A\n",
      "Your Eye, His Mind, His Hat\n",
      "Q: Name A Book That Every Child Should Be Made To Read.\n",
      "A: Lord Of The Flies.\n",
      "Q: Name A Man Who Would Be Described As A Born\n",
      "Name A Thing That You Can Keep For Years Without Spending A Single Penny.\n",
      "A: –\n",
      "\n",
      "Q: Name The World’s Greatest Sport (And Don’t Go In To Details, Just Name The\n",
      "or Table\n",
      "\n",
      "Q: Name A Man Who Needs A Roomier Suit More Often Than Most Women.\n",
      "A: A Man Who’s Married To A Woman With A Larger Bust\n",
      "\n",
      "Q: Name Something That’s L\n",
      "TRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<\n",
      "ame The Most Used House In The World.\n",
      "A: Bed\n",
      "\n",
      "Q: Name A Piece Of Furniture That’s Always In A House Even If It’s Not Being Used For A Special Occasion.\n",
      "A: Coffee\n",
      "ill\n",
      "\n",
      "Q: Name A Situation Where Not Doing Your Own Research Can Lead To You Getting A Bad Deal.\n",
      "A: House Hunting\n",
      "\n",
      "Q: Name The One Thing You Definitely Don’t Want A Stranger To Know About You\n",
      "Name Something A Politician Might Say That Has The Same Effect As The Magic Trick\n",
      "A: The Same Thing\n",
      "\n",
      "Q: Name Something A Person Might Be Able To Borrow From A Friend\n",
      "A: A Kidney\n",
      ") A Deck of Cards\n",
      "\n",
      "Q: Name Something We Always Use That Was Designed By A Woman\n",
      "A: (Bra) Lingerie\n",
      "\n",
      "Q: Name A Piece Of Furniture That Is Not A Chair\n",
      "A:\n",
      "k/24\n",
      "Q: Name A Group Of People Who Usually Attend A Barbecue.\n",
      "A: Family (and friends)\n",
      "Q: Name A Profession Which Is Most Likely To Make Your Wife Mad.\n",
      "A: Fireman\n",
      "Name One Of The Largest Rooms That Is Used For Public Meetings.\n",
      "A: Auditorium\n",
      "\n",
      "Q: Name Something You May Have A Lot Of In A House.\n",
      "A: Appliances\n",
      "\n",
      "Q: Name A Building That\n",
      "lion Pounds\n",
      "\n",
      "Q: Name Something You Might Find In The Trash.\n",
      "A: Old Fruit\n",
      "\n",
      "Q: Name Something You’d Say If You Saw Someone With Wet Pants :\n",
      "A: That Can’t Be Good\n",
      "2\n",
      "\n",
      "Q: Name Something People Might See In A Large Picture\n",
      "A: LARGE PICTURE\n",
      "\n",
      "Q: Name A Popular Snack\n",
      "A: Snacker\n",
      "\n",
      "Q: Name A Thing That Makes A Man Strong\n",
      "TRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<\n",
      "llars\n",
      "\n",
      "Q: Name Food That Has The Most Letters Of Anything People Usually Eat.\n",
      "A: Jellyfish\n",
      "\n",
      "Q: A Good Way To Get More From Life Is To Make The Most Of.\n",
      "A: Every Minute.\n",
      "llar Bill\n",
      "\n",
      "Q: Name Something That Has An Edge, A Point.\n",
      "A: Fork\n",
      "\n",
      "Q: Name A Sport That Uses A Bat.\n",
      "A: Baseball\n",
      "\n",
      "Q: Name A Job That Pays The Least.\n",
      "0.00\n",
      "\n",
      "Q: Name Something People Are Supposed To Put Their Money In, But Rarely Do So.\n",
      "A: Change\n",
      "\n",
      "Q: Name A Place That Is Often Cold, but You Can Sit Out-Side\n",
      "ill\n",
      "More from my site<|endoftext|>The Best Way to Get Rid of Mosquitos?\n",
      "I’ve been around for a while, and I believe I might be a bit wiser now than I was when I was younger and less inclined\n",
      "Q: Name A Job Where You Can Get Your Education For Free, After Working A Few Years.\n",
      "A: Doctor\n",
      "\n",
      "Q: Name Something That A Good Student Must Learn Early.\n",
      "A: Reading\n",
      "\n",
      "Q:\n"
     ]
    }
   ],
   "source": [
    "i = 37\n",
    "question = questions[i]\n",
    "print(question)\n",
    "responses = infer(sampling, template(question['question']), repeats=20)\n",
    "\n",
    "\n",
    "print(question['question'])\n",
    "print(*responses, sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T08:15:43.501421808Z",
     "start_time": "2023-07-19T08:14:18.481747610Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Name Something A Magician Might Make Disappear\n",
      "Reference answers: Rabbit, Assistant/Spectator, Bird, Money, Flowers, her/himself\n",
      "*************\n",
      "ng People Don\n",
      " The Job.\n",
      "A\n",
      "rn\n",
      "ame The\n",
      "hat’s L\n",
      "TION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<\n",
      ".\n",
      "A: Coffee\n",
      "Don’t Want A Stranger To Know About You\n",
      "w From A Friend\n",
      "A: A Kidney\n",
      "\n",
      "\n",
      "A: Fireman\n",
      "ame A Building That\n",
      "t Be Good\n",
      "\n",
      "TION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<>>INTRODUCTION<<\n",
      ".\n",
      "A: Every Minute.\n",
      "\n",
      "t-Side\n",
      "was when I was younger and less inclined\n",
      "\n",
      "A: Reading\n",
      "\n",
      "Q:\n"
     ]
    }
   ],
   "source": [
    "print(\"Q:\", questions[i]['question'])\n",
    "print(\"Reference answers:\", ', '.join([a['text'] for a in questions[i]['answers']]))\n",
    "print(\"*************\")\n",
    "print(*[r[150:] for r in responses], sep='\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T08:22:43.884905875Z",
     "start_time": "2023-07-19T08:22:43.883993458Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sbert = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "# print(responses)\n",
    "# print([a['text'] for a in question['answers']])\n",
    "# for i in range(5):\n",
    "#     question = questions[i]\n",
    "#     responses = infer(sampling, template(question['question']), repeats=6)\n",
    "#     similarities = util.cos_sim(sbert.encode(responses),  sbert.encode([a['text'] for a in question['answers']]))\n",
    "#     # plt.imshow(similarities.numpy(), cmap='plasma', vmin=0, vmax=1) #RdYlGn' gist_rainbow\n",
    "#     # plt.colorbar()\n",
    "#     # plt.title(i)\n",
    "#     # plt.show()\n",
    "#     for (id1, id2) in (similarities > 0.7).nonzero():\n",
    "#         print('--', similarities[id1, id2])\n",
    "#         print(question['question'])\n",
    "#         print(responses[id1])\n",
    "#         print(question['answers'][id2]['text'])\n",
    "SIMILARITY_THRESHOLD = 0.75\n",
    "def count_cover(responses, answers, similarity_threshold=SIMILARITY_THRESHOLD, encoder=sbert):\n",
    "    \"\"\"\n",
    "    Returns the share of answers that was guessed by responses\n",
    "    The similarity between answers and responses measured by cosine sim on encoder embeddings\n",
    "    Cut off by similarity threshold\n",
    "    Note, each response could \"cover\" only one answer with top similarity\n",
    "    Answer is considered guessed, if there are at least one reponse with similarity above threshold\n",
    "    \"\"\"\n",
    "    similarities = util.cos_sim(encoder.encode(responses), encoder.encode(answers))\n",
    "    max_sims = similarities * (similarities.max(dim=1).values[:, None] == similarities).float()\n",
    "    coverage = ((max_sims > similarity_threshold).float().mean(dim=0) > 0).float().mean()\n",
    "    return coverage"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:39:02.953435541Z",
     "start_time": "2023-07-11T11:39:01.969369172Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:39:02.965758508Z",
     "start_time": "2023-07-11T11:39:02.954398398Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def infer(func, prompt, repeats=5, verbose=False):\n",
    "    sep = \"\\n***********\\n\\n\"\n",
    "    if verbose:\n",
    "        print(prompt, end=sep)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "    input_ids = input_ids.repeat((repeats, 1))\n",
    "    gen_output = func(input_ids)\n",
    "    responses = [tokenizer.decode(sequence).replace('<unk>', '') for sequence in gen_output]\n",
    "    responses = [r[len(prompt) + 5:].strip() for r in responses]\n",
    "    if verbose:\n",
    "        print(*responses, sep=sep)\n",
    "    return responses\n",
    "\n",
    "\n",
    "# def sampling(tokens):\n",
    "#     return model.sample(\n",
    "#         tokens, logits_warper=logits_warper, max_length=80, eos_token_id=[2, 13]\n",
    "#     )\n",
    "\n",
    "def sampling(tokens):\n",
    "    return model.generate(tokens, max_new_tokens=50, eos_token_id=[2, 13], do_sample=True)\n",
    "\n",
    "\n",
    "def t2(q):\n",
    "    return q"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:39:03.228749638Z",
     "start_time": "2023-07-11T11:39:02.971032492Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.85 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "421 ms ± 214 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "responses = infer(sampling, template(question['question']), repeats=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T09:26:20.781398279Z",
     "start_time": "2023-07-11T09:26:17.366754154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "full template, 20 runs: 3.8s +- 600ms\n",
    "no template: 0.988s +- 280\n",
    "2 repeats: 246ms +- 235\n",
    "just tokenizer with token on cuda 2runs/20runs: 244us / 1.6ms\n",
    "cutted template, 20 runs, 2.8s +- 765ms\n",
    "cutted, 2 runs, 421ms\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RESTRICT = 20\n",
    "NUM_RUNS = 1\n",
    "# def sampling(tokens):\n",
    "#     return model.generate(tokens, max_new_tokens=50, eos_token_id=[2, 13], do_sample=True, top_k=2)\n",
    "def sampling(tokens):\n",
    "    return model.generate(tokens, max_new_tokens=50, eos_token_id=[13], do_sample=True, top_k=2)\n",
    "\n",
    "averages = []\n",
    "for _ in range(NUM_RUNS):\n",
    "    coverages = []\n",
    "    # for question in tqdm(questions[:RESTRICT]):\n",
    "    for question in tqdm(questions[10:11]):\n",
    "        answers = [a['text'] for a in question['answers']]\n",
    "        responses = infer(sampling, template(question['question']), repeats=10)\n",
    "        coverages.append(count_cover(responses, answers))\n",
    "\n",
    "        print(question['question'])\n",
    "        print(', '.join(answers))\n",
    "        print(*responses, sep=\"\\n\")\n",
    "\n",
    "\n",
    "    # print([c.item() for c in coverages])\n",
    "    # print(np.mean(coverages))\n",
    "    averages.append(np.mean(coverages))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "prompt = question['question']\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "input_ids = input_ids.repeat((1, 1))\n",
    "gen_outputs = model.generate(input_ids, max_new_tokens=1, eos_token_id=[13], do_sample=True)\n",
    "\n",
    "# responses = [tokenizer.decode(sequence).replace('<unk>', '') for sequence in gen_output]\n",
    "# responses = [r[len(prompt) + 5:].strip() for r in responses]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:39:03.228948189Z",
     "start_time": "2023-07-11T11:39:03.228598490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "SampleDecoderOnlyOutput(sequences=tensor([[    1,  4408, 12538,  3575,  1706,  1709,   341,   523,  3617,  4104,\n          2180,   887,   363,  1938,   292,  1763, 29877, 18927,   310, 18512,\n           306,   763,   304,   748,   278,  3353,   298,   468,   373,  1554,\n           297,  1749,  3699,   448,   322,  6041,   306,   679]],\n       device='cuda:0'), scores=(tensor([[   -inf,    -inf, 17.0358,  ...,    -inf,    -inf,    -inf]],\n       device='cuda:0'), tensor([[   -inf,    -inf, 16.4514,  ...,    -inf,    -inf,    -inf]],\n       device='cuda:0'), tensor([[   -inf,    -inf, 14.8860,  ...,    -inf,    -inf,    -inf]],\n       device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0')), attentions=None, hidden_states=None)"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(input_ids, max_new_tokens=20, eos_token_id=[13], top_p=0.95, do_sample=True, return_dict_in_generate=True, output_scores=True)\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:49:32.468874575Z",
     "start_time": "2023-07-11T11:49:31.749146680Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 32000])"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outputs.scores[0].topk(5)\n",
    "outputs.scores[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:49:55.431073972Z",
     "start_time": "2023-07-11T11:49:55.429022406Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "transition_scores = model.compute_transition_scores(\n",
    "    outputs.sequences, outputs.scores, normalize_logits=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:48:52.434363905Z",
     "start_time": "2023-07-11T11:48:52.424552410Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.8891]], device='cuda:0')"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_scores\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:48:53.657318102Z",
     "start_time": "2023-07-11T11:48:53.656906984Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[    1,  4408, 12538,  3575,  1706,  1709,   341,   523,  3617,  4104,\n          2180,   887,   363,  1938,   292,  1763, 29877, 18927]],\n       device='cuda:0')"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:49:06.354276794Z",
     "start_time": "2023-07-11T11:49:06.353409185Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[    1,  4408, 12538,  3575,  1706,  1709,   341,   523,  3617,  4104,\n          2180,   887,   363,  1938,   292,  1763, 29877, 18927,   310]],\n       device='cuda:0')"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.sequences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T11:49:20.686948534Z",
     "start_time": "2023-07-11T11:49:20.686129680Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Which Former President Would Look Funny Wearing A Dress?\n",
      "1 Name Something Your Spouse Might Get Mad At You for Doing Too Much\n",
      "2 What Kind Of Gift Would You Get Somebody That Spends A Lot Of Time At The Beach\n",
      "3 Name Something Millionaires Might Shop For Just For Fun\n",
      "4 Name An Item Stores Probably Have A Hard Time Selling After Christmas\n",
      "5 Name Something You Do In Front Of A Mirror You Wouldn’t Want Anyone To See\n",
      "6 Name Something That You Can Tell Is Fake In A Cheesy Movie\n",
      "7 Name Something Your Likely To Find At A Fall Harvest Fair\n",
      "8 name A fear parents Have For Their Child, When She Moves Out Of The House\n",
      "9 When Sitting Close To A Date, What Clue Might They Give That They Like \n",
      "10 Name An Instance When You Fake A Smile\n",
      "11 Name A Sign You’re At A Really Cheap Birthday party\n",
      "12 Name Something That Young Children Memorize\n",
      "13 Name Something A Hobo Does To Pass His Time While Ridin’ The Rails\n",
      "14 Other than Acting, Name A Profession That Celebrity Actors Might Take Up\n",
      "15 What Might A Rock Star Do At A Concert Hall That prevents Him Form Getting Hired Again\n",
      "16 Name Something You Should Never Wear As The Guest At Someone’s Wedding\n",
      "17 Name Something Men In Fairy Tales Fight Against, That Real Men Don’t\n",
      "18 Name A Movie Or TV Show That Has The word ‘Diary/Diaries’ In The Title\n",
      "19 We Asked 100 Married people: After How Many Did You Know Your Partner was The one?\n",
      "20 If A group Of Senior Citizens Formed A Punk Rock Band, What Might Their Songs Bark About\n",
      "21 Name A Job Where It Would Be Okay To Yell At Work\n",
      "22 Name A Sport In Which Participants Use A Specific Kind Of Headwear\n",
      "23 What Do People Do That Could Get Them Kicked Out Of A Museum\n",
      "24 Name Something That often Has Magical Powers In fairy Tales\n",
      "25 Name Something A Child Might Never Do If They weren’t Forced To\n",
      "26 Name Something That it’s Hard To Do While Listening To Music\n",
      "27 Name An Expression That Ends With The word “House”\n",
      "28 aside From Animals, Name Something People Hunt For.\n",
      "29 name Something A Celebrity Hopes Won’t Happen While On Stage To Accept An Award\n",
      "30 Name Something You Do In A Booth\n",
      "31 name something You Often Feel Sleepy while Doing\n",
      "32 Name A Reason Your Bathroom Is Better Than An Outhouse\n",
      "33 Name A Job Where Employees Must get Tired Arms\n",
      "34 Name A Specif Food That Someone With High Cholesterol Might give Up\n",
      "35 name A Way You Might Be Able to Tell Your Baby Is really An Alien\n",
      "36 What Might somebody Do That Would Annoy Fellow Theater-Goers At A Play?\n",
      "37 Name Something A Magician Might Make Disappear\n",
      "38 Name Something A Slob Might Never Clean\n",
      "39 Name A Popular Pick Up Line\n",
      "40 By What Method Might A Woman Make The Announcement That She’s Pregnant\n",
      "41 What Might An Adult Wear That Has His Name On It?\n",
      "42 Besides The Blade, Name Something You’d Find On A Swiss Army Knife\n",
      "43 Name Something Teens May Be Afraid Of When Moving Away To College\n",
      "44 name A Place You’d Visit More Often If It wasn’t So Crowded There\n",
      "45 Name A Place Where A Mom Might Go When She Says, ” I Need Peace And Quiet.”\n",
      "46 Name Something Around The House You Might Keep Spare Batteries For\n",
      "47 What Is The First Thing You Would Do If You Won A Million Dollars\n",
      "48 Name something That’s forbidden In Most Swimming Pools\n",
      "49 What Do Tourists Ride In Or On, That Makes Them Stand Out?\n"
     ]
    }
   ],
   "source": [
    "for i, q in enumerate(questions[:50]):\n",
    "    print(i, q['question'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T08:07:46.127302851Z",
     "start_time": "2023-07-19T08:07:45.820496988Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
