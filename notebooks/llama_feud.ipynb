{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"hi there\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:44:14.362436098Z",
     "start_time": "2023-07-10T11:44:11.832154841Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "from transformers import TemperatureLogitsWarper, LogitsProcessorList\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:44:14.362714240Z",
     "start_time": "2023-07-10T11:44:14.362186583Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e85c15c1ba64cc8a747b475566b0023"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)l-00002-of-00003.bin:   0%|          | 0.00/9.90G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5890e5bc58e6464193bc3afa910dc8fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)l-00003-of-00003.bin:   0%|          | 0.00/6.18G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f5ab0c101fc4faa868b47ef16ccf279"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ac8d5fa2321450d87fdfc4e0e75d11f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b00f9030b68144eb9671be696e689691"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(32000, 5120, padding_idx=0)\n    (layers): ModuleList(\n      (0-39): 40 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear(in_features=5120, out_features=5120, bias=False)\n          (k_proj): Linear(in_features=5120, out_features=5120, bias=False)\n          (v_proj): Linear(in_features=5120, out_features=5120, bias=False)\n          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear(in_features=5120, out_features=13824, bias=False)\n          (down_proj): Linear(in_features=13824, out_features=5120, bias=False)\n          (up_proj): Linear(in_features=5120, out_features=13824, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=5120, out_features=32000, bias=False)\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"huggyllama/llama-7b\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"huggyllama/llama-7b\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"lmsys/vicuna-13b-v1.3\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"lmsys/vicuna-13b-v1.3\")\n",
    "\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(\"lmsys/vicuna-7b-v1.3\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"lmsys/vicuna-7b-v1.3\")\n",
    "\n",
    "model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:54:03.783083926Z",
     "start_time": "2023-07-10T11:44:14.362661465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def recover_oom():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "recover_oom()\n",
    "\n",
    "\n",
    "def infer(func, prompt, repeats=5, verbose=False):\n",
    "    sep = \"\\n***********\\n\\n\"\n",
    "    if verbose:\n",
    "        print(prompt, end=sep)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "    input_ids = input_ids.repeat((repeats, 1))\n",
    "    gen_output = func(input_ids)\n",
    "    responses = [tokenizer.decode(sequence).replace('<unk>', '') for sequence in gen_output]\n",
    "    responses = [r[len(prompt) + 5:].strip() for r in responses]\n",
    "    if verbose:\n",
    "        print(*responses, sep=sep)\n",
    "    return responses\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:54:03.872294001Z",
     "start_time": "2023-07-10T11:54:03.872008400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# def sampling(tokens):\n",
    "#     return model.sample(\n",
    "#         tokens, logits_warper=logits_warper, max_length=80, eos_token_id=[2, 13]\n",
    "#     )\n",
    "\n",
    "def sampling(tokens):\n",
    "    return model.generate(tokens, max_new_tokens=50, eos_token_id=[2, 13], do_sample=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:54:03.956344155Z",
     "start_time": "2023-07-10T11:54:03.956124952Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13108\n",
      "Counter({6: 5019, 5: 3867, 4: 2935, 3: 1216, 2: 71})\n"
     ]
    }
   ],
   "source": [
    "# open the feud dataset\n",
    "import json\n",
    "\n",
    "with open('../data_store/question_db.json', 'r') as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "\n",
    "print(len(questions))\n",
    "lengths = [len(q['answers']) for q in questions]\n",
    "from collections import Counter\n",
    "print(Counter(lengths))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:54:04.062377520Z",
     "start_time": "2023-07-10T11:54:03.956215029Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "qs = [q for q in questions if len(q['answers']) == 3][:5]\n",
    "questions = [q for q in questions if len(q['answers']) == 6]\n",
    "# print(qa[0])\n",
    "# prompt = qa[0]['question']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:54:04.145402731Z",
     "start_time": "2023-07-10T11:54:04.062076962Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def template(prompt):\n",
    "    instruction = 'Your task is to play Family Feud. Provide one brief answer you believe the majority of people would agree with.\\n'\n",
    "    instruction += \"\\n\\n\".join([\n",
    "        f\"Question: {q['question']}\\nAnswer: {q['answers'][2]['text']}\" for q in qs[:5]\n",
    "    ])\n",
    "    instruction += f\"\\n\\nQuestion: {prompt}\\nAnswer: \"\n",
    "    return instruction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:54:04.145608055Z",
     "start_time": "2023-07-10T11:54:04.145231538Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Name Something Your Spouse Might Get Mad At You for Doing Too Much', 'link': '/question/name-something-your-spouse-might-get-mad-at-you-for-doing-too-much', 'answers': [{'text': 'Talking', 'points': 27}, {'text': 'Shopping/Spending', 'points': 21}, {'text': 'Drinking', 'points': 18}, {'text': 'Sleeping', 'points': 16}, {'text': 'Spending Money', 'points': 9}, {'text': 'Watching TV', 'points': 6}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 hours of TV', '', 'ing Too Frequently', '', 'BBQing', '']\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "question = questions[i]\n",
    "print(question)\n",
    "responses = infer(sampling, template(question['question']), repeats=6)\n",
    "print(responses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:54:19.176332345Z",
     "start_time": "2023-07-10T11:54:04.145559550Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sbert = SentenceTransformer(\"all-mpnet-base-v2\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:54:20.883726628Z",
     "start_time": "2023-07-10T11:54:19.176165723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 hours of TV', '', 'ing Too Frequently', '', 'BBQing', '']\n",
      "['Talking', 'Shopping/Spending', 'Drinking', 'Sleeping', 'Spending Money', 'Watching TV']\n"
     ]
    }
   ],
   "source": [
    "print(responses)\n",
    "print([a['text'] for a in question['answers']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:54:20.884021714Z",
     "start_time": "2023-07-10T11:54:20.883442221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     question = questions[i]\n",
    "#     responses = infer(sampling, template(question['question']), repeats=6)\n",
    "#     similarities = util.cos_sim(sbert.encode(responses),  sbert.encode([a['text'] for a in question['answers']]))\n",
    "#     # plt.imshow(similarities.numpy(), cmap='plasma', vmin=0, vmax=1) #RdYlGn' gist_rainbow\n",
    "#     # plt.colorbar()\n",
    "#     # plt.title(i)\n",
    "#     # plt.show()\n",
    "#     for (id1, id2) in (similarities > 0.7).nonzero():\n",
    "#         print('--', similarities[id1, id2])\n",
    "#         print(question['question'])\n",
    "#         print(responses[id1])\n",
    "#         print(question['answers'][id2]['text'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:54:21.094626623Z",
     "start_time": "2023-07-10T11:54:20.889932269Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "SIMILARITY_THRESHOLD = 0.75\n",
    "def count_cover(responses, answers, similarity_threshold=SIMILARITY_THRESHOLD, encoder=sbert):\n",
    "    \"\"\"\n",
    "    Returns the share of answers that was guessed by responses\n",
    "    The similarity between answers and responses measured by cosine sim on encoder embeddings\n",
    "    Cut off by similarity threshold\n",
    "    Note, each response could \"cover\" only one answer with top similarity\n",
    "    Answer is considered guessed, if there are at least one reponse with similarity above threshold\n",
    "    \"\"\"\n",
    "    similarities = util.cos_sim(encoder.encode(responses), encoder.encode(answers))\n",
    "    max_sims = similarities * (similarities.max(dim=1).values[:, None] == similarities).float()\n",
    "    coverage = ((max_sims > similarity_threshold).float().mean(dim=0) > 0).float().mean()\n",
    "    return coverage\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T12:03:20.228112663Z",
     "start_time": "2023-07-10T12:03:19.929397737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "209edb0d784f46d18a3b0adee1b620b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which Former President Would Look Funny Wearing A Dress?\n",
      "['George W Bush', 'William Clinton', 'Abe Lincoln', 'Richard Nixon', 'George Washington', 'Ronald Reagan']\n",
      "['George W. Bush</s>', '2 George W. Bush', '2nd President Bill Clinton', '0. Grover Cleveland', '3</s>', '2 (George H.W. Bush)', '2 Ronald Reagan', '2', '', '4. Ulysses S. Grant', 'Benjamin Harrison', '', '2nd President of the United States Bill Clinton', '2</s>', 'President George Washington</s>', '4', '5', '', 'nd George W. Bush / 44th Barack Obama or 45th Donald Trump', '3</s>']\n",
      "Name Something Your Spouse Might Get Mad At You for Doing Too Much\n",
      "['Talking', 'Shopping/Spending', 'Drinking', 'Sleeping', 'Spending Money', 'Watching TV']\n",
      "['난', 'Working too much', '', '', '不得回答）', '', '', '', '', '', '.', 'Betting On Sports Games', '不在规范。', '-Play Xbox Games', '', '. Over Spending', '', '-Year-Old’s Birthday Party</s>', '', '. Clean the whole house']\n",
      "What Kind Of Gift Would You Get Somebody That Spends A Lot Of Time At The Beach\n",
      "['Towel', 'Bathing Suit', 'Sun Screen', 'Umbrella', 'Sunglasses', 'Beach Chair']\n",
      "['', 'Bowls - 1 for Shells, 1 for Sand', '5,000 Mile American Airlines Gold AAdvantage Platinum Visa Signature Credit Card from Barclaycard</s>', 'Beach Towels</s>', '0L Volcano Beer Cooler', '5x40 Sunbrella Umbrella</s>', '-Pack Of Beach Towels</s>', 'FT Umbrella Beach Sun Shelter', '', '2-Pack Of Baguettes', 'Beach Towels', '', 'Piece Shower Curtain Rod Set', '️ Beach Towel', '. Beach Glasses', '️ Beach Towel', '', 'Foot Long Surfboard', 'Beach Towel', '-in-1 Umbrella & Beach Chair Combination</s>']\n",
      "Name Something Millionaires Might Shop For Just For Fun\n",
      "['cars', 'Clothes', 'Houses', 'Jewlery', 'Plane', 'boat']\n",
      "['020 Maserati GranTurismo Convertible</s>', '5 foot yacht', '8-karat Gold-plated Golf Clubs', '0 Foot Yacht', '926 Bugatti Type 35 Grand Prix Racing Car', '6', '00-foot Yacht', '4K Gold Golf Balls', '00 Foot Yacht.', '021 Bugatti La Voiture Noire (worth 18.7 million dollars)</s>', '019 Bugatti La Voiture Noire (worth $18.9 million)', '8-Karat Gold-Plated Toilet Paper Holder', '0’ Yacht', '. Exotic Cars', '5-foot-tall Luxury Yachts', '0,000 Dollar Cigar', '</s>', '5 ft Yacht', '. Bentley Car', '57 Private Jet</s>']\n",
      "Name An Item Stores Probably Have A Hard Time Selling After Christmas\n",
      "['Trees', 'Ornaments', 'Toys', 'Lights', 'Wrapping Paper', 'Christmas Cards']\n",
      "['9cent Candles</s>', '2 Days of Christmas Gifts</s>', '5 Foot Long Inflatable Slide', '2 Foot Long Christmas Lights', '5 Gallon Drum', 'ft Faux Fur Tree Christmas Decoration.', '-Prong Mop Bucket', '5 Foot Long Inflatable Santa', '9.99% of people would say: Decorative Tree', '0 Gallon Drum of Candy Canes', '0-Foot-Long Inflatable Santa', 'Tier Bamboo Stem Mini Rice Cookers', '-Gallon Bucket', '5 Foot Rolls of Wrapping Paper', '0 Inch TV', 'lb Box Of Crackers', '00 Foot Long Yard Sale Ribbon', 'gallon buckets', '0 Lb Bag Of Candy.</s>', '2 Foot Long Yellow Gift Box.']\n",
      "Name Something You Do In Front Of A Mirror You Wouldn’t Want Anyone To See\n",
      "['Pop A Zit', 'Look At Your Body', 'Dance', 'Undress', 'Pluck eyebrows', 'Clip Nose Hairs']\n",
      "['欢 (Belly Dance)', '', '. Yawning; 2. Sneezing; 3. Brushing Your Teeth', '. Pick nose', '</s>', 'brushing my teeth', '2. Bad Hair Day', '. Brushing Teeth', 'nd Answer: You’re not supposed to give two answers for a question unless explicitly told you can.</s>', '. Brush Teeth 3. Put on Makeup 4. Adjust Clothing', '骨折（Trick question, it’s 毛骨骨折, a type of chiropractic adjustment, not what most people would answer', 'rd answer in this format:', '', '', 'Brushing Teeth', 'nd Place', '0 seconds of awkward silence.', ') Brushing Teeth 2) Applying Sunscreen', '. Brushing Teeth', 'Personal grooming']\n",
      "Name Something That You Can Tell Is Fake In A Cheesy Movie\n",
      "['Blood', 'Love Scenes', 'Scenery', 'Acting', 'Monsters', 'Fight Scenes']\n",
      "['D Computer Graphics</s>', 'D Effects</s>', '0s CGI.</s>', 'D.', 'D Effects', 'D</s>', 'D</s>', 'D', 'D, 4D, or 5D', '/11 Scene', 'D.</s>', ': Acting</s>', 'D Hologram', '', 'D', 'D Objects', 'D</s>', ': Asteroid Belt. It’s not just the asteroids, it’s the way they move. They’re too perfect. 2A: When a monster is attacking a city on the big screen and', 'D', '0’s Haircut']\n",
      "Name Something Your Likely To Find At A Fall Harvest Fair\n",
      "['Pumpkins', 'Corn', 'Leaves', 'Apples', 'People', 'Hay Rides']\n",
      "['', 'Bonfire', '', '', '', '', 'Pumpkin', 'Bumper Cars</s>', '', '', '🎃🎃</s>', '', 'Cider', '0. Corn', 'Cider', '', '', '', '🍯', 'Pumpkins']\n",
      "name A fear parents Have For Their Child, When She Moves Out Of The House\n",
      "['Money', 'Drugs', 'Death', 'Safety', 'Coming Back', 'Lonely']\n",
      "['. Boyfriend/Girlfriend', ') Boyfriend, 2) Girlfriend, 3) Bad Influence', '', 'Bed-wetting', 'ोरिए छोड़', '', '. Boyfriend', '8', 'Being Eaten By A Lion.', '1st Century', '', 'ίαση (bullying)', '', 'BOYS', 'Boyfriend', '', '-Abandonment', '. Bulimia', '4,20', 'Boyfriend, 2- Girlfriend, 3- Alcohol, 4- Drugs']\n",
      "When Sitting Close To A Date, What Clue Might They Give That They Like \n",
      "['Holds Your hand', 'kisses You', 'Smiling', 'Arm Around You', 'Move Closer', 'Looking At You']\n",
      "['', '', '', '', '', '', '', 'You', '| 2 | 3 | 4 | 5', '', '', 'Biting Their Nails', 'Scratching Their Arm; 2. Fidgeting; 3. Leaning In', 'The other Person', '', '. Touching You Lightly 2. Eye Contact 3. Leaning In.', '. They smile a lot 2. They play with their hair 3. They lean in close', '', '', '']\n",
      "Name An Instance When You Fake A Smile\n",
      "['Having A Photo Taken', 'Hear A Bad Joke', 'Job Interview', 'Upset', 'Meeting New People', 'Nervous']\n",
      "['', 'hours (for a photo shoot)</s>', '. For A Photo', '0 AM Meeting', '', '2 Angry Men', '. At A Family Gathering', '', 'st Date</s>', '. Weddings', 'To Greet Someone You’re Not Happy To See', 'st Date', '', '. When The Camera Is On You', '', '. When Meeting New People', '1 years', '. At A Funeral 2. When Meeting Your Ex-Partner</s>', 'st Date', '']\n",
      "Name A Sign You’re At A Really Cheap Birthday party\n",
      "['No Cake', 'No food', 'No Decorations', 'No favors', 'No Presents', 'No cards']\n",
      "['9 Cent Store Decorations</s>', '0th birthday decorations</s>', 'Candle', '6 balloons</s>', '0 balloons', '5-cent Pinata', '0 Pin Bowling', 'Bucks Shy Of Disaster</s>', '9¢ Store Decorations', '0th Themed Table Decorations', '-Up', 'Balloons', 'foot Subway sandwich', 'balloon', '4 Candles On The Cake', '5-cent Wearable Gift (pinata, sunglasses)</s>', '9 cent store decorations', '-Liter of Coke.</s>', '5 Cent Pinata</s>', '0 watt light bulb']\n",
      "Name Something That Young Children Memorize\n",
      "['Alphabet', 'Spell Their Name', 'Phone Number', 'Address', 'Nursery Rhymes', 'Pledge Of Allegiance']\n",
      "['times table', '2-3-4-5-6-7-8-9-10', ', 2, 3, 4, 5', 'X Table</s>', '23s, ABCs', '23’s</s>', 'x table', '23', '23’s', 'Rs', 'plus 2 equals 4', 'x Table', 'x Table', 'times table', ',2,3,4,5', ', 2, 3, 4, 5', '23s (Counting)', '+2=4', 'Little Pigs', '+2=4']\n",
      "Name Something A Hobo Does To Pass His Time While Ridin’ The Rails\n",
      "['Sleep', 'Sing', 'Drink Alcohol', 'Eat', 'Talk', 'Read']\n",
      "[': Play Harmonica', '', '', '', '', 'Playing Harmonica', '', '. Reads A Newspaper', '. Playing Harmonica (28%), 4. Panhandling (27%), 5. Doodling (22%), 6. Singing (11%)</s>', '.</s>', '', '6. Read', '9. Singing.', '', '', '2', '', '. Play Harmonica', '-String Banjo', ')Play Music. 2)Tell Jokes. 3)Sing']\n",
      "Other than Acting, Name A Profession That Celebrity Actors Might Take Up\n",
      "['Singing', 'Directing', 'Modeling', 'Fashion design', 'Politics', 'Spokeperson']\n",
      "['.', '. Musician 2. Writer', '. Writing, 2. Directing, 3. Producing', '', '. Directing, 2. Writing, 3. Producing, 4. Musician', '. Writer 4. Director', '. Golf, 2. Cooking, 3. Singing, 4. Painting, 5. Writing</s>', '. Politics', 'Racing Cars, 2. Directing, 3. Sports Commentary, 4. Musician, 5. Businessman', '', '. Painting', '', '. Writing', '. Musician 2. Writer 3. Politics</s>', '. Singing', '', ') Carpenter 2) Chef 3) Writer(novel/journalism)</s>', ') Singing 2) Directing</s>', '', '']\n"
     ]
    }
   ],
   "source": [
    "RESTRICT = 20\n",
    "NUM_RUNS = 5\n",
    "def sampling(tokens):\n",
    "    return model.generate(tokens, max_new_tokens=50, eos_token_id=[2, 13], do_sample=True)\n",
    "\n",
    "averages = []\n",
    "for _ in range(NUM_RUNS):\n",
    "    coverages = []\n",
    "    for question in tqdm(questions[:RESTRICT]):\n",
    "        answers = [a['text'] for a in question['answers']]\n",
    "        responses = infer(sampling, template(question['question']), repeats=20)\n",
    "        coverages.append(count_cover(responses, answers))\n",
    "\n",
    "        print(question['question'])\n",
    "        print(answers)\n",
    "        print(responses)\n",
    "\n",
    "\n",
    "    print([c.item() for c in coverages])\n",
    "    print(np.mean(coverages))\n",
    "    averages.append(np.mean(coverages))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-07-10T12:03:23.358841528Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "averages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
